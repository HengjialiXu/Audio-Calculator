{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "#documentation: https://librosa.github.io/librosa/generated/librosa.feature.mfcc.html\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import logfbank\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import scipy.io.wavfile as wav\n",
    "import glob\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find relative path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qan96\\Documents\\GitHub\\Audio-Calculator\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.getcwd().endswith(\"Calculator\") == True or \\\n",
    "   os.getcwd().endswith(\"Calculator\\\\\") == True or \\\n",
    "   os.getcwd().endswith(\"Calculator/\") == True :\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxilary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 830,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_features(mfcc, fbank):\n",
    "    features = np.concatenate((mfcc, fbank), axis=1)\n",
    "    return features\n",
    "\n",
    "truncate_threshold = 0.1\n",
    "truncate_size = 10000.0\n",
    "pre_emphasis = 0.97\n",
    "\n",
    "def normalize(signal):\n",
    "    result = abs(signal).copy().astype('float64')\n",
    "    xmin = np.min(result)\n",
    "    xmax = np.max(result)\n",
    "    for i in range(0, signal.size):\n",
    "        result[i] = (result[i] - xmin) / (xmax - xmin)\n",
    "        result[i] = \"%.2f\" % result[i]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def calculate_normalized_entropy(signal):\n",
    "    #normalize\n",
    "    signal = normalize(signal)\n",
    "    \n",
    "    p = np.zeros(101)\n",
    "    for i in range(0, signal.size):\n",
    "        p[(signal[i] / 0.01).astype('int64')] += 1\n",
    "    \n",
    "    p = p / signal.size\n",
    "    max_entro = 0.0\n",
    "    min_entro = 1.0\n",
    "    entropy = np.zeros(signal.size)\n",
    "    \n",
    "    for i in range(0, signal.size):\n",
    "        index = (signal[i] / 0.01).astype('int64')\n",
    "        entropy[i] = -p[index]*math.log2(p[index])\n",
    "        max_entro = max(max_entro, entropy[i])\n",
    "        min_entro = min(min_entro, entropy[i])\n",
    "        \n",
    "    for i in range(0,100):\n",
    "        if p[i] == 0:\n",
    "            continue\n",
    "        #print(-p[i]*math.log2(p[i]))\n",
    "        \n",
    "    lamb = (max_entro - min_entro) / 2.0\n",
    "    return entropy, lamb\n",
    "    \n",
    "def plot_sig(sig, ylabel):\n",
    "    plt.figure()\n",
    "    plt.plot(sig)\n",
    "    plt.xlabel(\"time [s]\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "\n",
    "def preprocess(sig, enable_plot = False, pre_emphasis = False):\n",
    "    if enable_plot == True:\n",
    "        plot_sig(sig, \"before pre-emphasis\")\n",
    "        \n",
    "    if pre_emphasis == True:\n",
    "        sig = np.append(sig[0], sig[1:] - pre_emphasis * sig[:-1])\n",
    "    \n",
    "    if enable_plot == True:\n",
    "        plot_sig(sig, \"after pre-emphasis\")\n",
    "        \n",
    "    start_point = 0\n",
    "    threshold = 0.1\n",
    "    norm_sig = normalize(sig)\n",
    "    np.set_printoptions(threshold=sys.maxsize)\n",
    "    \n",
    "    for i in range(0, sig.size):\n",
    "        if norm_sig[i] >= truncate_threshold:\n",
    "            start_point = i\n",
    "            break\n",
    "    \n",
    "    stop_point = sig.size\n",
    "    for i in reversed(range(0, sig.size)):\n",
    "        if norm_sig[i] >= (truncate_threshold):\n",
    "            stop_point = i\n",
    "            break\n",
    "    \n",
    "    #print(\"start point\", start_point)\n",
    "    #print(\"stop point\", stop_point)\n",
    "    sig = sig[start_point:stop_point]\n",
    "    #print(sig.size)\n",
    "    \n",
    "    #strech sig to 6000\n",
    "    sig = librosa.core.resample(sig, sig.size, truncate_size)\n",
    "    \n",
    "    if enable_plot == True:\n",
    "        plot_sig(sig, \"after truncation and resampling\")\n",
    "    #sig = truncate_sig(sig)\n",
    "    \n",
    "    return sig\n",
    "    \n",
    "def read_file(files, label, enable_plot=False):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for file in files:\n",
    "        (rate,sig) = wav.read(file)\n",
    "        \n",
    "        sig, sample_rate = librosa.core.load(file)\n",
    "        #entropy, lamb = calculate_normalized_entropy(sig)\n",
    "        \n",
    "        sig = preprocess(sig, enable_plot)\n",
    "        \n",
    "        mfcc_feat = mfcc(sig, rate, nfft=1536)\n",
    "        fbank_feat = logfbank(sig, rate, nfft=1536)    \n",
    "        acoustic_features = join_features(mfcc_feat, fbank_feat)\n",
    "        acoustic_features = acoustic_features.flatten()\n",
    "        features.append(acoustic_features)\n",
    "        labels.append(label)\n",
    "        \n",
    "    return features, labels\n",
    "        \n",
    "digit_feature_types = [\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\",\\\n",
    "                 \"nine\"]\n",
    "\n",
    "feature_types = [\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\",\\\n",
    "                 \"nine\", \"plus\", \"minus\", \"times\", \"over\"]\n",
    "\n",
    "op_feature_types = [\"plus\", \"minus\", \"times\", \"over\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero finished\n",
      "one finished\n",
      "two finished\n",
      "three finished\n",
      "four finished\n",
      "five finished\n",
      "six finished\n",
      "seven finished\n",
      "eight finished\n",
      "nine finished\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qan96\\Anaconda3\\lib\\site-packages\\scipy\\io\\wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plus finished\n",
      "minus finished\n",
      "times finished\n",
      "over finished\n",
      "Input and preprocessing finished\n"
     ]
    }
   ],
   "source": [
    "digit_features = []\n",
    "digit_labels = []\n",
    "op_features = []\n",
    "op_labels = []\n",
    "for i in digit_feature_types:\n",
    "    if sys.platform.startswith('win32'):\n",
    "         os.chdir(cwd+\"\\\\recording data\\\\\" + i + \"\\\\\")\n",
    "    elif sys.platform.startswith('darwin'):\n",
    "         os.chdir(cwd+\"/recording data/\" + i + \"/\")\n",
    "    \n",
    "    files = glob.glob(os.path.join(os.getcwd(), '*.wav') )\n",
    "    features, labels = read_file(files, i, False)\n",
    "    digit_features.extend(features)\n",
    "    digit_labels.extend(labels)\n",
    "    print(i, \"finished\")\n",
    "\n",
    "for i in op_feature_types:\n",
    "    if sys.platform.startswith('win32'):\n",
    "         os.chdir(cwd+\"\\\\recording data\\\\\" + i + \"\\\\\")\n",
    "    elif sys.platform.startswith('darwin'):\n",
    "         os.chdir(cwd+\"/recording data/\" + i + \"/\")\n",
    "    \n",
    "    files = glob.glob(os.path.join(os.getcwd(), '*.wav') )\n",
    "    features, labels = read_file(files, i, False)\n",
    "    op_features.extend(features)\n",
    "    op_labels.extend(labels)\n",
    "    \n",
    "    print(i, \"finished\")\n",
    "    \n",
    "print(\"Input and preprocessing finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backup raw features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "digit_features = np.asarray(digit_features)\n",
    "digit_labels = np. asarray(digit_labels)\n",
    "op_features = np.asarray(op_features)\n",
    "op_labels = np. asarray(op_labels)\n",
    "\n",
    "digit_features_backup = digit_features.copy()\n",
    "digit_labels_backup = digit_labels.copy()\n",
    "op_features_backup = op_features.copy()\n",
    "op_labels_backup = op_labels.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve features from backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 4836)\n",
      "(2000,)\n",
      "(389, 4836)\n",
      "(389,)\n"
     ]
    }
   ],
   "source": [
    "digit_features = digit_features_backup.copy()\n",
    "digit_labels = digit_labels_backup.copy()\n",
    "\n",
    "print(digit_features.shape)\n",
    "print(digit_labels.shape)\n",
    "\n",
    "print(op_features.shape)\n",
    "print(op_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#validate features and labels\n",
    "for i in range(1, digit_features.shape[0]):\n",
    "    if digit_features[i].size != digit_features[0].size:\n",
    "        print(\"digit features\", i)\n",
    "        print(digit_features[i].size)\n",
    "    if digit_labels[i].size != 1:\n",
    "        print(\"digit labels\", i)\n",
    "        print(digit_labels[i].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization and PCA feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "# digit_scaler = StandardScaler()\n",
    "# # Fit on training set only.\n",
    "# digit_scaler.fit(digit_features)\n",
    "\n",
    "# digit_train_set = digit_scaler.transform(digit_train_set)\n",
    "# digit_test_set = digit_scaler.transform(digit_test_set)\n",
    "\n",
    "# digit_pca = PCA(.95)\n",
    "# digit_pca.fit(digit_features)\n",
    "# digit_train_set = digit_pca.transform(digit_train_set)\n",
    "# digit_test_set = digit_pca.transform(digit_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1714, 4836)\n",
      "(286, 4836)\n"
     ]
    }
   ],
   "source": [
    "print(digit_train_set.shape)\n",
    "print(digit_test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "digit_train_set, digit_test_set, digit_train_label, digit_test_label = train_test_split(digit_features, digit_labels, test_size=1.0/7.0, random_state=0, stratify=digit_labels)\n",
    "op_train_set, op_test_set, op_train_label, op_test_label = train_test_split(op_features, op_labels, test_size=1.0/7.0, random_state=0, stratify=op_labels)\n",
    "print(digit_features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy:  82.16783216783216 %\n",
      "train set accuracy:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "digit_logisticRegr = LogisticRegression(multi_class = 'multinomial', solver = 'lbfgs', penalty = 'l2', max_iter = 10000)\n",
    "\n",
    "digit_logisticRegr.fit(digit_train_set, digit_train_label)\n",
    "\n",
    "print(\"test set accuracy: \", digit_logisticRegr.score(digit_test_set, digit_test_label) * 100, \"%\")\n",
    "print(\"train set accuracy: \", digit_logisticRegr.score(digit_train_set, digit_train_label) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy:  92.85714285714286 %\n",
      "train set accuracy:  100.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qan96\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "op_logisticRegr = LogisticRegression(multi_class = 'multinomial', solver = 'lbfgs', penalty = 'l2')\n",
    "\n",
    "op_logisticRegr.fit(op_train_set, op_train_label)\n",
    "\n",
    "print(\"test set accuracy: \", op_logisticRegr.score(op_test_set, op_test_label) * 100, \"%\")\n",
    "print(\"train set accuracy: \", op_logisticRegr.score(op_train_set, op_train_label) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set accuracy:  92.85714285714286 %\n",
      "train set accuracy:  100.0 %\n"
     ]
    }
   ],
   "source": [
    "# for i in range(0, op_test_set.shape[0]):\n",
    "#     if test_label[i] in op_feature_types:\n",
    "#         result = op_logisticRegr.predict(op_test_set[i].reshape(1,-1))\n",
    "#         if (result != op_test_label[i]):\n",
    "#             print(\"Correct result:\" + op_test_label[i])\n",
    "#             print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9025\n"
     ]
    }
   ],
   "source": [
    "digit_rfc = RandomForestClassifier(n_estimators = 150)\n",
    "X_train, X_val, y_train, y_val = train_test_split(digit_features, digit_labels, test_size=0.2, random_state=10, shuffle = True, stratify=digit_labels)\n",
    "\n",
    "digit_rfc.fit(X_train, y_train)\n",
    "#checking the accuracy of the model\n",
    "print(digit_rfc.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9487179487179487\n"
     ]
    }
   ],
   "source": [
    "op_rfc = RandomForestClassifier(n_estimators = 150)\n",
    "X_train, X_val, y_train, y_val = train_test_split(op_features, op_labels, test_size=0.2, random_state=10, shuffle = True, stratify=op_labels)\n",
    "op_rfc.fit(X_train, y_train)\n",
    "\n",
    "#checking the accuracy of the model\n",
    "print(op_rfc.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting\n",
      "digit svm fitting...\n",
      "svm digit test accuracy =0.948\n",
      "svm digit train accuracy =1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(digit_features, digit_labels, test_size=0.2, random_state=10, shuffle = True, stratify=digit_labels)\n",
    "\n",
    "#print(X_train)\n",
    "\n",
    "print(\"digit svm fitting...\")\n",
    "\n",
    "digit_svm = SVC(C=20.0, gamma=0.00001)\n",
    "digit_svm.fit(X_train, y_train)\n",
    "dig_test_acc = digit_svm.score(X_val, y_val)\n",
    "dig_train_acc = digit_svm.score(X_train, y_train)\n",
    "print(\"svm digit test accuracy =%0.3f\" % dig_test_acc)\n",
    "print(\"svm digit train accuracy =%0.3f\" % dig_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['times' 'over' 'plus' 'plus' 'times' 'minus' 'over' 'minus' 'over'\n",
      " 'minus' 'minus' 'times' 'plus' 'times' 'plus' 'over' 'over' 'plus' 'over'\n",
      " 'minus' 'times' 'plus' 'over' 'minus' 'times' 'plus' 'times' 'over'\n",
      " 'plus' 'minus' 'times' 'minus' 'times' 'times' 'over' 'plus' 'minus'\n",
      " 'over' 'minus' 'times' 'plus' 'plus' 'minus' 'plus' 'times' 'plus'\n",
      " 'times' 'minus' 'times' 'times' 'minus' 'plus' 'times' 'over' 'plus'\n",
      " 'minus' 'plus' 'plus' 'minus' 'plus' 'plus' 'plus' 'plus' 'plus' 'plus'\n",
      " 'over' 'plus' 'over' 'minus' 'minus' 'minus' 'plus' 'plus' 'minus'\n",
      " 'minus' 'plus' 'over' 'minus' 'times' 'minus' 'plus' 'plus' 'times'\n",
      " 'minus' 'plus' 'minus' 'over' 'minus' 'times' 'over' 'over' 'over' 'over'\n",
      " 'minus' 'times' 'minus' 'over' 'minus' 'minus' 'minus' 'times' 'minus'\n",
      " 'times' 'times' 'plus' 'plus' 'over' 'times' 'plus' 'times' 'over' 'over'\n",
      " 'times' 'times' 'over' 'minus' 'minus' 'times' 'minus' 'plus' 'plus'\n",
      " 'minus' 'plus' 'plus' 'minus' 'minus' 'minus' 'plus' 'minus' 'plus'\n",
      " 'times' 'minus' 'minus' 'over' 'over' 'times' 'plus' 'minus' 'over'\n",
      " 'times' 'plus' 'times' 'minus' 'times' 'minus' 'minus' 'plus' 'times'\n",
      " 'times' 'over' 'minus' 'plus' 'times' 'minus' 'times' 'over' 'over'\n",
      " 'over' 'over' 'times' 'minus' 'times' 'minus' 'plus' 'times' 'plus'\n",
      " 'over' 'times' 'times' 'plus' 'over' 'over' 'plus' 'times' 'times' 'plus'\n",
      " 'minus' 'plus' 'minus' 'plus' 'plus' 'times' 'minus' 'over' 'over' 'over'\n",
      " 'minus' 'over' 'plus' 'times' 'over' 'over' 'plus' 'over' 'plus' 'times'\n",
      " 'over' 'minus' 'times' 'over' 'minus' 'over' 'times' 'times' 'over'\n",
      " 'minus' 'minus' 'times' 'minus' 'over' 'times' 'over' 'minus' 'times'\n",
      " 'times' 'times' 'over' 'over' 'plus' 'plus' 'times' 'minus' 'over' 'plus'\n",
      " 'minus' 'times' 'over' 'over' 'times' 'over' 'times' 'over' 'over' 'over'\n",
      " 'over' 'times' 'over' 'plus' 'plus' 'over' 'times' 'over' 'times' 'plus'\n",
      " 'minus' 'over' 'over' 'times' 'times' 'over' 'over' 'times' 'times'\n",
      " 'times' 'over' 'over' 'plus' 'over' 'plus' 'over' 'minus' 'over' 'over'\n",
      " 'times' 'minus' 'over' 'over' 'times' 'times' 'minus' 'minus' 'times'\n",
      " 'minus' 'plus' 'minus' 'over' 'over' 'plus' 'plus' 'minus' 'times'\n",
      " 'times' 'minus' 'minus' 'over' 'times' 'minus' 'over' 'times' 'plus'\n",
      " 'times' 'over' 'times' 'times' 'minus' 'minus' 'times' 'plus' 'over'\n",
      " 'times' 'minus' 'plus' 'plus' 'minus' 'minus' 'minus' 'plus' 'over'\n",
      " 'plus' 'minus' 'minus']\n",
      "operator svm fitting...\n",
      "svm operator test accuracy=0.936\n",
      "svm operator train accuracy=1.000\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(op_features, op_labels, test_size=0.2, random_state=10, shuffle = True, stratify=op_labels)\n",
    "\n",
    "print('operator svm fitting...')\n",
    "op_svm = SVC(C=20.0, gamma=0.00001)\n",
    "op_svm.fit(X_train, y_train)\n",
    "op_test_acc = op_svm.score(X_val, y_val)\n",
    "op_train_acc = op_svm.score(X_train, y_train)\n",
    "print(\"svm operator test accuracy=%0.3f\" % op_test_acc)\n",
    "print(\"svm operator train accuracy=%0.3f\" % op_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digit adaboost with logistic fitting...\n",
      "digit adaboost with logistic test accuracy =0.833\n",
      "digit adaboost with logistic train accuracy =1.000\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(digit_features, digit_labels, test_size=0.2, random_state=10, shuffle = True, stratify=digit_labels)\n",
    "\n",
    "#print(X_train)\n",
    "\n",
    "print(\"digit adaboost with logistic fitting...\")\n",
    "\n",
    "digit_ada_log = AdaBoostClassifier(LogisticRegression(multi_class = 'multinomial', solver = 'lbfgs', penalty = 'l2', max_iter = 10000), n_estimators=100, random_state=0)\n",
    "digit_ada_log.fit(X_train, y_train)\n",
    "dig_test_acc = digit_ada_log.score(X_val, y_val)\n",
    "dig_train_acc = digit_ada_log.score(X_train, y_train)\n",
    "print(\"digit adaboost with logistic test accuracy =%0.3f\" % dig_test_acc)\n",
    "print(\"digit adaboost with logistic train accuracy =%0.3f\" % dig_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting\n",
      "digit adaboost with random forest fitting...\n",
      "digit adaboost with random forest test accuracy =0.895\n",
      "digit adaboost with random forest train accuracy =1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(digit_features, digit_labels, test_size=0.2, random_state=10, shuffle = True, stratify=digit_labels)\n",
    "\n",
    "#print(X_train)\n",
    "\n",
    "print(\"digit adaboost with random forest fitting...\")\n",
    "\n",
    "digit_ada_rf = AdaBoostClassifier(RandomForestClassifier(n_estimators = 150), n_estimators=100, random_state=0)\n",
    "digit_ada_rf.fit(X_train, y_train)\n",
    "dig_test_acc = digit_ada_rf.score(X_val, y_val)\n",
    "dig_train_acc = digit_ada_rf.score(X_train, y_train)\n",
    "print(\"digit adaboost with random forest test accuracy =%0.3f\" % dig_test_acc)\n",
    "print(\"digit adaboost with random forest train accuracy =%0.3f\" % dig_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting\n",
      "operator adaboost with logistic fitting...\n",
      "operator adaboost with logistic test accuracy =0.936\n",
      "operator adaboost with logistic train accuracy =1.000\n"
     ]
    }
   ],
   "source": [
    "print(\"Splitting\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(op_features, op_labels, test_size=0.2, random_state=10, shuffle = True, stratify=op_labels)\n",
    "\n",
    "print(\"operator adaboost with logistic fitting...\")\n",
    "\n",
    "op_ada_log = AdaBoostClassifier(LogisticRegression(multi_class = 'multinomial', solver = 'lbfgs', penalty = 'l2', max_iter = 10000), n_estimators=100, random_state=0)\n",
    "op_ada_log.fit(X_train, y_train)\n",
    "op_test_acc = op_ada_log.score(X_val, y_val)\n",
    "op_train_acc = op_ada_log.score(X_train, y_train)\n",
    "print(\"operator adaboost with logistic test accuracy =%0.3f\" % op_test_acc)\n",
    "print(\"operator adaboost with logistic train accuracy =%0.3f\" % op_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "operator adaboost with random forest fitting...\n",
      "operator adaboost rf test accuracy =0.949\n",
      "operator adaboost rf train accuracy =1.000\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(op_features, op_labels, test_size=0.2, random_state=10, shuffle = True, stratify=op_labels)\n",
    "\n",
    "print(\"operator adaboost with random forest fitting...\")\n",
    "\n",
    "op_ada_rf = AdaBoostClassifier(RandomForestClassifier(n_estimators = 150), n_estimators=100, random_state=0)\n",
    "op_ada_rf.fit(X_train, y_train)\n",
    "op_test_acc = op_ada_rf.score(X_val, y_val)\n",
    "op_train_acc = op_ada_rf.score(X_train, y_train)\n",
    "print(\"operator adaboost rf test accuracy =%0.3f\" % op_test_acc)\n",
    "print(\"operator adaboost rf train accuracy =%0.3f\" % op_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"svm\", \"logistic\", \"rf\", \"adaboost with rf\", \"adaboost with logistic\"]\n",
    "\n",
    "def read_and_test_file(directory, t = \"digit\", enable_plot = False):\n",
    "    os.chdir(cwd+\"\\\\recording data\\\\\"+directory)\n",
    "    files = glob.glob(os.path.join(os.getcwd(), '*.wav') )\n",
    "    file_n = 0\n",
    "    for file in files:\n",
    "        file_n = file_n + 1\n",
    "        now = t\n",
    "        if now == \"formula\":\n",
    "            if file_n % 2 == 1:\n",
    "                now = \"digit\"\n",
    "            else:\n",
    "                now = \"operator\"\n",
    "        (rate,sig) = wav.read(file)\n",
    "        sig, sample_rate = librosa.core.load(file)\n",
    "        sig = preprocess(sig)\n",
    "        mfcc_feat = mfcc(sig, rate, nfft=1536)\n",
    "        fbank_feat = logfbank(sig, rate, nfft=1536)\n",
    "        \n",
    "        acoustic_features = mfcc_feat\n",
    "        acoustic_features = join_features(mfcc_feat, fbank_feat)\n",
    "        acoustic_features = acoustic_features.flatten()\n",
    "        result = []\n",
    "        if now == \"digit\":\n",
    "            #acoustic_features = digit_scaler.transform(acoustic_features.reshape(1,-1))\n",
    "            #acoustic_features = digit_pca.transform(acoustic_features)\n",
    "            #print(acoustic_features.shape)\n",
    "            result.append(digit_svm.predict(acoustic_features.reshape(1, -1)))\n",
    "            result.append(digit_logisticRegr.predict(acoustic_features.reshape(1,-1)))\n",
    "            result.append(digit_rfc.predict(acoustic_features.reshape(1,-1)))\n",
    "            result.append(digit_ada_rf.predict(acoustic_features.reshape(1,-1)))\n",
    "            result.append(digit_ada_log.predict(acoustic_features.reshape(1,-1)))\n",
    "        else:\n",
    "            result.append(op_svm.predict(acoustic_features.reshape(1, -1)))\n",
    "            result.append(op_logisticRegr.predict(acoustic_features.reshape(1,-1)))\n",
    "            result.append(op_rfc.predict(acoustic_features.reshape(1,-1)))\n",
    "            result.append(op_ada_rf.predict(acoustic_features.reshape(1,-1)))\n",
    "            result.append(op_ada_log.predict(acoustic_features.reshape(1,-1)))\n",
    "                            \n",
    "        print(file)\n",
    "        count = np.zeros(10)\n",
    "        \n",
    "        for i in range(0, 5):\n",
    "            print(models[i], result[i])\n",
    "            if now == \"digit\":\n",
    "                for j in range(0, 10):\n",
    "                    if digit_feature_types[j] == result[i]:\n",
    "                        count[j] = count[j] + 1\n",
    "                        if i >= 3:\n",
    "                            count[j] = count[j] + 1\n",
    "                        break\n",
    "            if now == \"operator\":\n",
    "                for j in range(0, 5):\n",
    "                    if op_feature_types[j] == result[i]:\n",
    "                        count[j] = count[j] + 1\n",
    "                        if i >= 3:\n",
    "                            count[j] = count[j] + 1\n",
    "                        break\n",
    "                        \n",
    "        if t == \"formula\":\n",
    "            if file_n == 1:\n",
    "                digit1 = np.argmax(count)\n",
    "            if file_n == 2:\n",
    "                op = np.argmax(count)\n",
    "            if file_n == 3:\n",
    "                digit2 = np.argmax(count)\n",
    "                print(\"\\nFormula acquired!\")\n",
    "                print(\"The formula is: \", digit1, op_feature_types[op], digit2)\n",
    "                \n",
    "                if op == 0:\n",
    "                    print(\"The answer is:\", digit1 + digit2)\n",
    "                if op == 1:\n",
    "                    print(\"The answer is:\", digit1 - digit2)\n",
    "                if op == 2:\n",
    "                    print(\"The answer is:\", digit1 * digit2)\n",
    "                if op == 3:\n",
    "                    if digit2 == 0:\n",
    "                        print(\"denominator couldn't be 0\")\n",
    "                    else:\n",
    "                        print(\"The answer is:\", digit1 / digit2)\n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qan96\\Documents\\GitHub\\Audio-Calculator\\recording data\\formula\\1.wav\n",
      "svm ['nine']\n",
      "logistic ['six']\n",
      "rf ['five']\n",
      "adaboost with rf ['five']\n",
      "adaboost with logistic ['seven']\n",
      "C:\\Users\\qan96\\Documents\\GitHub\\Audio-Calculator\\recording data\\formula\\2.wav\n",
      "svm ['plus']\n",
      "logistic ['plus']\n",
      "rf ['plus']\n",
      "adaboost with rf ['plus']\n",
      "adaboost with logistic ['plus']\n",
      "C:\\Users\\qan96\\Documents\\GitHub\\Audio-Calculator\\recording data\\formula\\3.wav\n",
      "svm ['four']\n",
      "logistic ['one']\n",
      "rf ['four']\n",
      "adaboost with rf ['four']\n",
      "adaboost with logistic ['one']\n",
      "\n",
      "Formula acquired!\n",
      "The formula is:  5 plus 4\n",
      "The answer is: 9\n"
     ]
    }
   ],
   "source": [
    "read_and_test_file(\"formula\", \"formula\", False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'op_ada_log' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-822-04e4837bffe9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mread_and_test_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"op_test\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"op\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-819-3c0f245f48b9>\u001b[0m in \u001b[0;36mread_and_test_file\u001b[1;34m(directory, t, enable_plot)\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_rfc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macoustic_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_ada_rf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macoustic_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_ada_log\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macoustic_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'op_ada_log' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
