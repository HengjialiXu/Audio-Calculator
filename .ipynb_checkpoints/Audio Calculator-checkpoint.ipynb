{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#documentation: https://librosa.github.io/librosa/generated/librosa.feature.mfcc.html\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from python_speech_features import mfcc\n",
    "from python_speech_features import logfbank\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import scipy.io.wavfile as wav\n",
    "import glob\n",
    "import sys\n",
    "import numpy as np\n",
    "import parselmouth\n",
    "import math\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qan96\\Documents\\GitHub\\Audio-Calculator\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.getcwd().endswith(\"Calculator\") == True or \\\n",
    "   os.getcwd().endswith(\"Calculator\\\\\") == True or \\\n",
    "   os.getcwd().endswith(\"Calculator/\") == True :\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qan96\\Anaconda3\\lib\\site-packages\\scipy\\io\\wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    }
   ],
   "source": [
    "def join_features(mfcc, fbank):\n",
    "    features = np.concatenate((mfcc, fbank), axis=1)\n",
    "    return features\n",
    "\n",
    "truncate_size = 6000\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "def normalize(signal):\n",
    "    result = abs(signal).copy().astype('float64')\n",
    "    xmin = np.min(result)\n",
    "    xmax = np.max(result)\n",
    "    for i in range(0, signal.size):\n",
    "        result[i] = (result[i] - xmin) / (xmax - xmin)\n",
    "        result[i] = \"%.2f\" % result[i]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def calculate_normalized_entropy(signal):\n",
    "    #normalize\n",
    "    signal = normalize(signal)\n",
    "    \n",
    "    p = np.zeros(101)\n",
    "    for i in range(0, signal.size):\n",
    "        p[(signal[i] / 0.01).astype('int64')] += 1\n",
    "    \n",
    "    p = p / signal.size\n",
    "    max_entro = 0.0\n",
    "    min_entro = 1.0\n",
    "    entropy = np.zeros(signal.size)\n",
    "    \n",
    "    for i in range(0, signal.size):\n",
    "        index = (signal[i] / 0.01).astype('int64')\n",
    "        entropy[i] = -p[index]*math.log2(p[index])\n",
    "        max_entro = max(max_entro, entropy[i])\n",
    "        min_entro = min(min_entro, entropy[i])\n",
    "        \n",
    "    for i in range(0,100):\n",
    "        if p[i] == 0:\n",
    "            continue\n",
    "        #print(-p[i]*math.log2(p[i]))\n",
    "        \n",
    "    lamb = (max_entro - min_entro) / 2.0\n",
    "    return entropy, lamb\n",
    "    \n",
    "def plot_sig(sig, ylabel):\n",
    "    plt.figure()\n",
    "    plt.plot(sig)\n",
    "    plt.xlabel(\"time [s]\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "    \n",
    "def truncate_sig(sig):\n",
    "    if sig.size >= truncate_size:\n",
    "        sig = sig[:truncate_size]\n",
    "    else:\n",
    "        sig = np.concatenate((sig, np.zeros(truncate_size - sig.size)))\n",
    "    return sig\n",
    "\n",
    "def read_file(files, label):\n",
    "    for file in files:\n",
    "        (rate,sig) = wav.read(file)\n",
    "        \n",
    "        #plot_sig(sig, amplitude)\n",
    "        \n",
    "        labels.append(label)\n",
    "        sample_rate, sig = scipy.io.wavfile.read(file)  # File assumed to be in the same directory\n",
    "        \n",
    "        #entropy, lamb = calculate_normalized_entropy(sig)\n",
    "        \n",
    "        pre_emphasis = 0.97\n",
    "        sig = np.append(sig[0], sig[1:] - pre_emphasis * sig[:-1])\n",
    "        \n",
    "        start_point = 0\n",
    "#         for i in range(0, entropy.size):\n",
    "#             print(entropy[i])\n",
    "#             if entropy[i] > lamb:\n",
    "#                 start_point = i\n",
    "#                 break\n",
    "                \n",
    "        threshold = 0.1\n",
    "        norm_sig = normalize(sig)\n",
    "        #print(norm_sig)\n",
    "        for i in range(0, sig.size):\n",
    "            #print(norm_sig[i])\n",
    "            if norm_sig[i] >= threshold:\n",
    "                start_point = i\n",
    "                break\n",
    "                \n",
    "        #print(start_point)\n",
    "        sig = sig[start_point:]\n",
    "        \n",
    "        sig = truncate_sig(sig)\n",
    "    \n",
    "        #plot_sig(sig, \"amplitude after truncate\")\n",
    "        \n",
    "        mfcc_feat = mfcc(sig, rate, nfft=1536)\n",
    "        fbank_feat = logfbank(sig, rate, nfft=1536)\n",
    "        acoustic_features = join_features(mfcc_feat, fbank_feat)\n",
    "        features.append(acoustic_features)\n",
    "        \n",
    "        #print(acoustic_features.size)\n",
    "        \n",
    "feature_types = [\"zero\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\",\\\n",
    "                 \"nine\", \"plus\", \"minus\", \"times\", \"over\"]\n",
    "\n",
    "for i in feature_types:\n",
    "    if sys.platform.startswith('win32'):\n",
    "         os.chdir(cwd+\"\\\\recording data\\\\\" + i + \"\\\\\")\n",
    "    elif sys.platform.startswith('darwin'):\n",
    "         os.chdir(cwd+\"/recording data/\" + i + \"/\")\n",
    "    \n",
    "    files = glob.glob(os.path.join(os.getcwd(), '*.wav') )\n",
    "    read_file(files, i)\n",
    "\n",
    "print(\"Feature vector constructed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n",
      "[[ 1.90280096e+01 -1.77589723e+01 -1.32748363e+01 ...  1.49078145e+01\n",
      "   1.50141811e+01  1.58236857e+01]\n",
      " [ 1.92829643e+01 -2.13836573e+01 -2.10375464e+01 ...  1.51639470e+01\n",
      "   1.54474483e+01  1.61188383e+01]\n",
      " [ 1.94613698e+01 -2.30469344e+01 -2.83711807e+01 ...  1.49294234e+01\n",
      "   1.51355956e+01  1.57507491e+01]\n",
      " ...\n",
      " [-3.60436534e+01  0.00000000e+00 -3.20763172e-14 ... -3.60436534e+01\n",
      "  -3.60436534e+01 -3.60436534e+01]\n",
      " [-3.60436534e+01  0.00000000e+00 -3.20763172e-14 ... -3.60436534e+01\n",
      "  -3.60436534e+01 -3.60436534e+01]\n",
      " [-3.60436534e+01  0.00000000e+00 -3.20763172e-14 ... -3.60436534e+01\n",
      "  -3.60436534e+01 -3.60436534e+01]]\n"
     ]
    }
   ],
   "source": [
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "2057\n",
      "2057\n"
     ]
    }
   ],
   "source": [
    "np.asarray(features)\n",
    "np.asarray(labels)\n",
    "\n",
    "\n",
    "train_set, test_set, train_label, test_label = train_test_split(features, labels, test_size=1.0/7.0, random_state=0)\n",
    "\n",
    "print(type(train_set))\n",
    "print(len(train_set))\n",
    "print(len(train_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-5e77cd6ef07c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlogisticRegr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'lbfgs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlogisticRegr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Predict for One Observation (image)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[1;32m-> 1532\u001b[1;33m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[0;32m   1533\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1534\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    720\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    494\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m                 \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression(solver = 'lbfgs')\n",
    "\n",
    "logisticRegr.fit(train_set, train_label)\n",
    "\n",
    "# Predict for One Observation (image)\n",
    "print(logisticRegr.predict(test_set[0].reshape(1,-1)))\n",
    "\n",
    "# Predict for One Observation (image)\n",
    "#logisticRegr.predict(test_set[0:10])\n",
    "\n",
    "print(logisticRegr.score(test_set, test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
